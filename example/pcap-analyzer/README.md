# üß† PCAP Analyzer ‚Äî Architecture & Logic Overview

> **Self-healing network forensics pipeline built with FastAPI and multi-agent orchestration.**  
> Automatically generates, executes, and repairs PCAP analysis scripts within an isolated sandbox environment.

---

## üìò 1. Overview

**PCAP Analyzer** is a **network traffic analysis service** built with **FastAPI**.  
It combines **multi-agent collaboration** with an **automatic repair loop** to achieve a fully autonomous, AI-assisted forensic workflow.

**Core Objective:**  
> Automatically generate, execute, and repair analysis scripts to realize a self-healing forensic automation pipeline.

### üîÑ Workflow Summary

1. **Planner Agent** ‚Äî Generates a one-shot Bash analysis script.  
2. **SandboxRunner** ‚Äî Uploads the script and PCAP into a secure sandbox and executes it.  
3. **Reporter Agent** ‚Äî Analyzes execution logs and produces a structured Markdown report.  
4. If the script fails, the **system automatically enters a repair loop**, where the Planner Agent revises and retries the script until successful or until retries are exhausted.

---

## ‚öôÔ∏è 2. System Architecture

### üß© FastAPI Service

- Exposes a single REST endpoint: **`POST /analyze`**  
- **Input:** `pcap_file` (upload) or `pcap_path` (local file path)  
- **Output:**
  - `script` ‚Äî Final Bash script generated by the LLM  
  - `results` ‚Äî Execution logs and command outputs  
  - `report` ‚Äî Human-readable Markdown summary report  

---

### ü§ñ Planner Agent

- **Role:** Network forensics expert  
- **Task:** Generate a self-contained Bash script that analyzes `/workspace/pocket.pcap`  
- **Output Format:**
  ```json
  { "script": "..." }
  ```

**Prompt Templates:**
| Template | Description |
|-----------|--------------|
| `PLANNER_SYSTEM` | Defines rules and required output format |
| `PLANNER_USER` | Injects runtime context and PCAP path |
| `PLANNER_REPAIR_USER` | Used in repair stage, includes error logs and the previous script |

---

### üßÆ Reporter Agent

- **Role:** Forensic analyst  
- **Task:** Convert raw execution results into a structured Markdown report  

**Report Sections:**
1. Executive Summary  
2. Capture Overview  
3. Conversations  
4. Endpoints  
5. Protocol Distribution  
6. Notable Findings  
7. Recommendations  
8. Command Log  

---

## üß± 3. SandboxRunner

### Responsibilities

- Creates, initializes, executes, and shuts down a remote sandbox instance.  
- Wraps execution results into a consistent, JSON-friendly structure:

```json
{
  "stdout": "...",
  "stderr": "...",
  "exitCode": 0,
  "isError": false
}
```

### Key Methods

| Method | Purpose |
|---------|----------|
| `upload_file()` / `upload_bytes()` | Uploads local files or data blobs into the sandbox |
| `run(command)` | Executes a shell command inside the sandbox |
| `stop()` | Gracefully shuts down the sandbox environment |

---

## üîÅ 4. Automatic Repair Mechanism

### üß© Step 1 ‚Äî Single Execution (`_execute_once_in_runner()`)

After uploading the PCAP and generated script, the sandbox runs:

```bash
chmod +x /workspace/plan.sh
/bin/bash /workspace/plan.sh
```

Each execution produces two command logs (chmod + run).

---

### üß© Step 2 ‚Äî Repair Logic (`_repair_script()`)

When a script fails:

- Injects the `stderr`, `exitCode`, and previous script into the repair prompt (`PLANNER_REPAIR_USER`).  
- The Planner Agent outputs a revised script.  
- The system automatically retries execution.

---

### üß© Step 3 ‚Äî Main Loop (`_analyze_with_retries()`)

Within one sandbox session:

1. Execute the initial script.  
2. If failure occurs, request Planner to repair and re-execute.  
3. Continue up to **`max_retries + 1` rounds** (default: 3 attempts).  
4. Aggregate all results for the Reporter Agent to process.

**Pseudocode:**
```python
for attempt in range(max_retries + 1):
    result = execute(script)
    if success(result):
        break
    else:
        script = repair(script, result)
```

---

## üí° 5. Prompt Template Design Philosophy

| Prompt | Purpose | Core Concept |
|---------|----------|--------------|
| `PLANNER_SYSTEM` | Defines Planner rules | Generate Bash script, non-interactive, JSON-only output |
| `PLANNER_USER` | Task context | Analyze `/workspace/pocket.pcap` |
| `PLANNER_REPAIR_USER` | Auto-repair phase | Include failure logs and previous script |
| `REPORTER_SYSTEM` | Defines Reporter behavior | Markdown report structure |
| `REPORTER_USER` | Report template | Includes command logs and execution JSON |

**Design Highlights:**

- **Strict JSON output** ‚Äî prevents parsing or formatting issues  
- **Fixed Bash header:**
  ```bash
  #!/usr/bin/env bash
  set -euo pipefail
  ```
- **Fault-tolerant logic:**  
  Handles missing tools gracefully (`command -v tshark || true`),  
  uses `|| true` to preserve pipeline stability.

---

## üß≠ 6. Server Logic

### Startup Sequence

- Initializes the `ChatOpenAI` LLM client  
- Creates **Planner** and **Reporter** agents  
- Loads configurations from environment variables (e.g., `OPENAI_API_KEY`, `OPENAI_MODEL`, etc.)

### `/analyze` Request Flow

1. Save uploaded PCAP file (if provided).  
2. Call `_plan_script()` ‚Üí Generate initial script.  
3. Call `_analyze_with_retries()` ‚Üí Execute and auto-repair as needed.  
4. Call `_report()` ‚Üí Produce Markdown report.  
5. Return consolidated results (`script`, `results`, `report`).

---

## ‚öôÔ∏è 7. Configurable Parameters

| Environment Variable | Description | Default |
|----------------------|-------------|----------|
| `OPENAI_API_KEY` | LLM API key | *Required* |
| `OPENAI_MODEL` | Model name | `Qwen/QwQ-32B` |
| `OPENAI_API_BASE` | Model API endpoint | `https://api.siliconflow.cn/v1` |
| `SANDBOX_NAMESPACE` | Sandbox namespace | `default` |
| `SANDBOX_CPU` / `SANDBOX_MEMORY` | Resource allocation | `200m` / `256Mi` |
| `SANDBOX_WARMUP_SEC` | Sandbox warm-up time (seconds) | `20` |
| `PLANNER_MAX_RETRIES` | Maximum auto-repair attempts | `2` |
| `DEBUG_SAVE_DIR` | Debug artifact output directory | `./debug_artifacts` |

---

## üß© Summary

**PCAP Analyzer** provides a complete **AI-driven PCAP analysis workflow**, integrating:  
- Autonomous script generation  
- Sandboxed execution  
- Intelligent repair and retry cycles  
- Automated Markdown report generation  

This creates a fully automated, fault-tolerant, and self-healing forensic analysis service accessible via a simple REST API.

---

### üß± Tech Stack

- **Backend:** FastAPI, Uvicorn  
- **AI Runtime:** LangChain + LangGraph + ChatOpenAI  
- **Execution Environment:** Custom Sandbox (agentcube)  
- **Language:** Python 3.11+

---

### üß∞ Example Run

#### build image
```bash
cd example/pcap-analyzer
docker build -t "pcap-analyzer:latest" -f Dockerfile ../../
```

#### build deploy
```yaml
cd example/pcap-analyzer
sed -i 's/my-openai-api-key/{your-api-key}/g' deployment.yaml
kubectl apply -f deployment.yaml
```

#### request
Obtain the pod IP by running the command "kubectl get pod -owide | grep pcap-analyzer". "./samples/pocket.pcap" need change to your file path.
```bash
curl -X POST "http://{pod_ip}:8000/analyze"   -H "Content-Type: application/x-www-form-urlencoded"   -d "pcap_file=@./samples/pocket.pcap""
```

Response:
```json
{
  "script": "#!/usr/bin/env bash\nset -euo pipefail\n...",
  "results": [...],
  "report": "# Executive Summary\n..."
}
```

---

### üßë‚Äçüíª Author & License

Maintained by **LeslieKuo  
ü™™ License: *Specify here* (e.g., MIT, Apache 2.0)
